---
title: "Week 4 Reading Guide Part 1: Linear regression with a single predictor"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Section 7.1 -- Fitting a line, residuals, and correlation

In the equation $y = b_0 + b_1 \times x + e$ what do the following represent?

__$y$__

</br>
</br>

__$b_0$__

</br>
</br>

__$b_1$__

</br>
</br>

What then is $\beta_0$?

</br>
</br>

What is $\beta_1$?

</br>
</br>

__Predictor:__

</br>
</br>

__Outcome:__

</br>
</br>

---

In the example of possum head lengths and total lengths, describe the following:

__predictor variable:__

</br>

__outcome variable:__

</br>

__direction of relationship:__

</br>

__strength of relationship:__

</br>

---

### 7.1.3

__Residual:__

</br>
</br>

### 7.1.4

__Correlation:__

</br>
</br>

__$\rho$:__ population correlation 

__$r$:__ sample correlation

</br>

What values can the correlation have? 

</br>

What does a positive correlation suggest about the relationship between x and y?

</br>
</br>

What does a negative correlation suggest about the relationship between x and y?

</br>
</br>

---

## 7.2 -- Least squares regression

What method is used to find the "best" least squares line?

</br>
</br>

__Sample slope interpretation:__ a 1 unit increase in the *x*-variable is
associated with a $|b_1|$ unit *predicted* increase/decrease in the mean of the
*y*-variable.

</br>

__Sample intercept interpretation:__ when the *x*-variable is 0, $b_0$ is the 
*predicted* mean of the *y*-variable.

</br>

### 7.2.4

__Extrapolation:__

</br>
</br>

### 7.2.5

__R-squared / Coefficient of determination:__

</br>
</br>

---

## 7.3 -- Outliers in linear regression

Where does an outlier with "high leverage" fall on a scatterplot?

</br>
</br>

What does it mean for an outlier to be "influential"?

</br>
</br>

Where would an outlier with "high influence" fall on a scatterplot?

</br>
</br>

---

## Reminders from previous chapters

__Scatterplot:__ displays two quantitative variables; one dot = two measurements
($x$, $y$) on one observational unit.

__Four characteristics of a scatterplot:__

* *Form*: pattern of the dots plotted.  Is the trend generally linear (you can fit a straight line to the data) or non-linear?  
* *Strength*: how closely do the points follow a trend?  Very closely (strong)? No pattern (weak)?  
* *Direction*: as the $x$ values increase, do the $y$-values tend to increase (positive) or decrease (negative)?  
* Unusual observations or *outliers*: points that do not fit the overall pattern of the data. 

__General steps of a hypothesis test:__

1. Frame the research question in terms of hypotheses.

2. Collect and summarize data using a test statistic.
	
3. Assume the null hypothesis is true, and simulate or mathematically model a null distribution for the test statistic.

4. Compare the observed test statistic to the null distribution to calculate a p-value.

5. Make a conclusion based on the p-value and write the conclusion in context.

__Parameter:__ a value summarizing a variable(s) for a population.

__Statistic:__ a value summarizing a variable(s) for a sample.

__Sampling distribution:__ plot of statistics from 1000s of samples of the same size
taken from the same population.

__Standard deviation of a statistic:__ the variability of statistics from 1000s
of samples; how far, on average, each statistic is from the true value of the parameter.

__Standard error of a statistic:__ estimated standard deviation of a statistic.

__Null hypothesis ($H_0$):__ the skeptical perspective; no difference; no
change; no effect; random chance; what the researcher hopes to demonstrate is
**wrong**.

__Alternative hypothesis ($H_A$):__ the new perspective; a
difference/increase/decrease; an effect; not random chance; what the researcher
hopes to demonstrate is **correct**.

__Null value:__ the value of the parameter when we assume the null hypothesis is
true (labeled as $parameter_0$).

__Null distribution:__  the simulated or modeled distribution of statistics
(sampling distribution) we would expect to occur if the null hypothesis is true.

__P-value:__ probability of seeing the observed sample data, or something more
extreme, assuming the null hypothesis is true.

$\implies$ Lower the p-value the stronger the evidence AGAINST the null hypothesis and FOR the alternative hypothesis.

__Decision:__ a determination of whether to reject or fail to reject a null
hypothesis based on a p-value and a pre-set level of significance.

* If p-value $\leq \alpha$, then reject $H_0$.

* If p-value $> \alpha$, then fail to reject $H_0$.

__Significance level ($\alpha$):__ a threshold used to determine if a p-value
provides enough evidence to reject the null hypothesis or not.

- Common levels of $\alpha$ include 0.01, 0.05, and 0.10.

__Statistically significant:__ results are considered "statistically
significant" if the p-value is below the significance level.

__Confidence interval:__ a process to determine how large an effect is; a range
of plausible values for the parameter.

__Margin of error:__ the value that is added to and subtracted from the sample
statistic to create a confidence interval; half the width of a confidence
interval.

__Bootstrapping:__ the process of drawing with replacement $n$ times from the
original sample.

__Bootstrapped resample:__ a random sample of size $n$ from the original sample,
selected with replacement.

__Bootstrapped statistic:__ the statistic recorded from the bootstrapped 
resample.

__Confidence level:__ how confident we are that the confidence interval will
capture the parameter.

__Bootstrap $X$% confidence interval:__ ($(\frac{(1-X)}{2})^{th}$ percentile,
$(X+(\frac{(1-X)}{2})^{th}$ percentile) of a bootstrap distribution

__$t$-distribution:__ A bell-shaped symmetric distribution, centered at 0, wider
than the standard normal distribution.

* The variability in a $t$-distribution depends on the sample size (used to
calculate degrees of freedom --- df for short).
* The $t$-distribution gets closer to the standard normal distribution as df increases.

__Degrees of freedom (df):__ describes the variability of the $t$-distribution.

__T-score:__ the name for a standardized statistic which is compared to a $t$-distribution.
