---
title: "Chi-Square Test of Independence: Fatal Injuries in the Iliad"
output: html_document
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE)

library(tidyverse)
library(janitor)
library(infer)
```

## Learning outcomes

* Given a research question involving two categorical variables, construct the
null and alternative hypotheses in words and using appropriate statistical
symbols.
  
* Describe and perform a chi-square test of independence for two categorical
variables by:
  - Finding the expected counts
  - Calculating the $X^2$ statistic  

* Interpret and evaluate a p-value for a chi-square test of independence for two
categorical variables.

* Use mathematical conditions to determine whether simulation-based methods or 
theory-based methods should be used when obtaining a p-value.

## Fatal Injuries in the Iliad

Homerâ€™s Iliad is an epic poem, compiled around 800 BCE, that describes several
weeks of the last year of the 10-year siege of Troy (Ilion) by the Achaeans. The
story centers on the rage of the great warrior Achilles. But it includes many
details of injuries and outcomes, and is thus the oldest record of Greek
medicine. The data report 146 recorded injuries for which both injury site and
outcome are provided in the Iliad (Hutchinson, 2013). 

For this activity we will focus on assessing if the location of an injury is
associated with whether the injury was fatal. 

```{r data, include = FALSE}
iliad <- read_csv(
  here::here(
    "Week 9 - Two Cat Inference", 
    "activity", 
    "day1_independence", 
    "data", 
    "iliad.csv"
    )
  ) %>% 
  mutate(`Injury Site` = replace_na(`Injury Site`, "Unknown"), 
         `Injury Site` = if_else(`Injury Site` == "body", 
                                 "Body", 
                                 `Injury Site`)
  )

```


## Exploratory Data Analysis 


1. What is the explanatory variable?

\vspace{0.5in}

2. What is the response variable?

\vspace{0.5in}

3. What is the scope of inference for this study?

\newpage

### Visualizing the Data

To visualize the relationship between **two** categorical variables, we need
to add some color into our previous bar plots.  

Let's step through this process. Last week, we started with a one variable 
bar plot that looked like this:

```{r 1var-barplot}
ggplot(data = iliad, 
       mapping = aes(x = `Injury Site`)) + 
  geom_bar() + 
  labs(x = "Location of Injury from Iliad")
```

The problem is, these bars don't show whether each injury included in the bar
was fatal or nonfatal. To do this, we need to fill the bars with color, using 
the `fill` aesthetic.


In the code below, I've added a line that says `fill = Lethal`. This `fill`s
each bar with two colors, one for "Fatal" injuries and one for "Nonfatal"
injuries.

```{r 2var-barplot}
ggplot(data = iliad, 
       mapping = aes(x = `Injury Site`, 
                     fill = Lethal)) + 
  geom_bar() + 
  labs(x = "Location of Injury from Iliad")
```

4. How would you describe the orientation of this bar plot?   
*Hint:* The three choices are filled, stacked, and dodged

\vspace{0.5in}

If we want a different layout for our bar plot than what `geom_bar()` does by 
default, we will need to be more specific! This is where the `position` option
in `geom_bar()` comes in handy. There are three options for how the bars can 
be `position`ed:

- `"stack"` (the default)
- `"dodge"`
- `"fill"` 

Let's change the code to use a `dodge`d position instead of a `stack`ed
position.

```{r dodged-barplot}
ggplot(data = iliad, 
       mapping = aes(x = `Injury Site`, 
                     fill = Lethal)) + 
  geom_bar(position = "dodge") + 
  labs(x = "Location of Injury from Iliad")
```

5. Based on the plot does there appear to be an association between the
variables? Explain your answer.

\vspace{1in}


### Summarizing the Data

Bar plots are an excellent tool for giving us a bigger picture of the 
relationship between two variables. However, sometimes we would like to see 
the exact numbers going into the bars. This is when it would be useful for us
to have a table of the totals!

Like the bar plots, we will be adding to what we learned previously. In Lab 7, 
we made one variable tables using the following process:

```
myopia %>%
  group_by(Light) %>% 
  summarize(n = n())
```

This gave us a table of how many observations (children) in the dataset slept 
with no light, a nightlight, or full light. We could do something similar here:

```
iliad %>% 
  group_by(`Injury Site`) %>% 
  summarize(n = n()) 
```

```{r 1var-table, echo = FALSE}
iliad %>% 
  group_by(`Injury Site`) %>% 
  summarize(n = n()) %>% 
  knitr::kable()
```

But wait! This doesn't show how many of the 67 body injuries were fatal! 

6. Take a guess at how we can modify the code above to give us counts of 
**both** the injury location and whether the injury was fatal. 


```{r table-code-fill-in, eval = FALSE}
iliad %>% 
  group_by(_________________________) %>% 
  summarize(n = n()) 

```


\newpage

Nice work! You are correct, we need to `group_by()` **two** variables and then
`summarize` them. When we run the code you wrote this is what we get:

```{r 2var-table, echo = FALSE}
iliad %>% 
  group_by(`Injury Site`, Lethal) %>% 
  summarize(n = n()) %>% 
  knitr::kable()
```

7. Which injury location has the smallest number of observations?

\vspace{0.25in}

8. Were there more fatal injuries or nonfatal injuries?

\vspace{0.25in}


Unfortunately, these calculations are a bit difficult given the current layout 
of the table. What we need to do is move one of the variables (`Injury Site` or
`Lethal`) to the columns. We can do this using a fancy tool called
`pivot_wider()`!

I've added two lines of code to the previous table: 

```
iliad %>% 
  group_by(`Injury Site`, Lethal) %>% 
  summarize(n = n()) %>% 
  pivot_wider(names_from = `Injury Site`, 
              values_from = n) %>% 
  adorn_totals(where = c("row", "col"))
```
\vspace{0.25cm}

Let me talk you through what each of these lines does. 

\vspace{0.25cm}

```
pivot_wider(names_from = `Injury Site`, 
            values_from = n) %>% 
```
takes the names from the `Injury Site` column and makes four new columns based 
on the names from this column (`Body`, `Head/neck`, `Limb`, and `Unknown`). It 
fills each of those columns with the values found in the `n` column. 

\vspace{0.25cm}

```
adorn_totals(where = c("row", "col"))
```
takes the new table and adds a "Total" row at the bottom of the table and a
"Total" column on the far right side. 

The resulting table looks like this:

```{r pivoted-2var-table, echo = FALSE}
iliad %>% 
  group_by(`Injury Site`, Lethal) %>% 
  summarize(n = n()) %>% 
  pivot_wider(names_from = `Injury Site`, values_from = n) %>% 
  adorn_totals(where = c("row", "col")) %>% 
  knitr::kable()
```

Nice, right???

\vspace{0.25cm}

Use this new table to address the following questions.

9. What proportion of body injuries were fatal?

\vspace{0.5in}

10. What proportion of limb injuries were fatal?

\vspace{0.5in}

## Chi-Squared Test of Independence 

Similar to what we did last week with one categorical variable, we will be 
performing a Chi-Squared test to compare what we saw in the data to what
we would have expected to see if the null hypothesis was true.

11. Write the null hypothesis for this study in words.

\vspace{1in}

12. Using the research question, write the alternative hypothesis in words.

\vspace{1in}

### Expected Counts Under $H_0$ 

The Chi-Squared statistic (or $X^2$) has exactly the same formula to what we 
used last week. The only aspect that changes is how we get each cell's expected
count. 

To find the expected count for each cell in our two variable table, we
use three pieces of information:

- the row total for that cell
- the column total for that cell
- the total sample size 

We find the expected value of a cell using the following formula:

$$
\frac{\text{row total} \times \text{column total}}{\text{total sample size}}
$$

\vspace{0.25cm}

Once we have each of these, we can create a table of what frequencies we would
have expected to see if $H_0$ was true. 

13. I've gotten you started with the expected value table. Fill out the 
remainder of the table below!


| Lethal   | Body                         | Head/neck                   | Limb | Unknown |
|----------|------------------------------|-----------------------------|------|---------|
| Fatal    | $\frac{155*67}{184} = 56.44$ |                             |      |         | </br>
| Nonfatal |                              | $\frac{29*45}{184} = 7.09$  | $\frac{28*34}{184} = 5.36$ |


### Chi-Squared Statistic

Next, we compare each of our observed frequencies to what we would have expected
if $H_0$ was true. We compare how far "off" our observed frequencies are from 
what was expected in a very specific way, using the following calculation:

$$
\frac{(\text{observed} - \text{expected})^2}{\text{expected}}
$$

14. Using the formula above, calculate how far "off" each of the cells in our
observed table is from what was expected under the null hypothesis. 

\vspace{1in}


15. Adding all of these differences together to obtain our observed $X^2$
statistic. 

$X^2 =$

\vspace{0.5in}

## Sampling Distribution of $X^2$

In order for us to calculate our p-value---the probability of observing an $X^2$
statistic as or more extreme than what we got, if the null was true---we need a 
distribution of $X^2$ statistics that could have happened if $H_0$ was true.

Like all of our previous topics, there are two ways we can obtain this 
**sampling distribution**:

- using mathematical theory
- using computer simulation


Let's see how each of these works! 

## Theory-based Null Distribution

For the Chi-Squared test of independence we've been discussing, it can be
mathematically shown that the distribution of $X^2$ statistics follows a 
$\chi^2$ distribution with $(r - 1) \times (c - 1)$ degrees of freedom, 
where $r$ is the number of rows and $c$ is the number of columns in the table.

16. How many degrees of freedom would be use for our $\chi^2$ distribution?

\vspace{0.5in}

### The $\chi^2$ Distribution

We've seen the $\chi^2$ distribution before in the context of the
goodness-of-fit test. That is the same distribution we are using here! Recall,
the $\chi^2$ distribution has only positive values and the shape of the
distribution is controlled by its degrees of freedom.  

### Conditions for Using a $\chi^2$ Distribution

In order for the $\chi^2$ distribution to be a good approximation of the true
sampling distribution, we need to verify two conditions:

- The observations are independent
- We have a "large enough" sample size 
  * This is checked by verifying there are at least 5 expected counts in each
  cell

If the condition about expected cell counts is violated, we are forced to use
a simulation-based method.

17. Are the conditions for using a $\chi^2$ distribution to approximate the 
sampling distribution violated?

\vspace{0.5in}

### Using a $\chi^2$ Distribution to Find the p-value

If we decided in #17 that it is not unreasonable for us to use the $\chi^2$
distribution, then we can use `R` to find our p-value. 

We will use the `pchisq()` function, which has three inputs:

- the observed $X^2$ statistic
- how many degrees of freedom should be used for the $\chi^2$ distribution
- if the lower tail (left tail) should be used when calculating the p-value

18. Using the values you calculated before and your intuition, fill in the 
code below:

```{r chi-sq-p-value, echo = TRUE, eval = FALSE}
pchisq(_________, df = _____, lower.tail = FALSE)
```

\vspace{0.25in}

Running the code you just wrote in `R` gave me a p-value of approximately
`r round(pchisq(67.7, df = 3, lower.tail = FALSE), 6)`. 

19. Based on this p-value what conclusion would you reach regarding the null
hypothesis?
*Hint:* Go back and see what you wrote for your null and alternative
hypotheses in #11 and #12!

\vspace{1in}

## Simulated / Permuted Null Distribution

If the condition for expected counts is violated, we cannot use a $\chi^2$ 
distribution to approximate what the true sampling distribution looks like. 
Instead, we need to use computer simulation to obtain our p-value. 

Like all of the previous times, we can think about what the computer is doing
using cards. Keep in mind, we are assuming the null hypothesis is true, which 
suggests there is no relationship between the location of someone's injury and
whether they lived or died. 

\vspace{0.25in}

To carry out **one** simulation we need to do the following steps:

__Step 1:__ Write the response (died / didn't die) and the location of the 
injury (body / head / limb / unknown) on ______ cards. 

\vspace{0.25cm}

__Step 2:__ Assume the null hypothesis is true and: 

\vspace{1in}

__Step 3:__ Create a new dataset that could have happened if $H_0$ was true by:

\vspace{1in}

__Step 4:__ Create a table of the simulated counts for the shuffled cards. Keep 
in mind the **column** totals for the location of the injury will stay the 
**same** (there were only 34 people with limb injuries). However, the **row**
totals will **change** (we won't always have 61 fatalities for body injuries). 

\vspace{0.25cm}

__Step 5:__ Calculate the $X^2$ statistic for the simulation

\vspace{0.25in}

__Step 6:__ Plot the simulated $X^2$ statistic on the distribution

\vspace{0.25in}

Alright, after carrying out this process, I obtained the following distribution.

```{r null-dist, echo = FALSE}
iliad %>% 
  specify(response = Lethal, 
          explanatory = `Injury Site`) %>% 
  hypothesise(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "Chisq") %>% 
  visualize( ) + 
  labs(title = " ", 
            x = "Simulated X-Squared Statistics", 
            y = "Number of Simulations (out of 1000 reps)")
```

20. Draw a line where the observed $X^2$ statistic falls on this distribution.

\vspace{0.25in}

21. Estimate the p-value for testing if there is a relationship between the
location of an injury and whether the individual survived. 

\vspace{0.25in}

22. Based on your p-value, what would you conclude for your null and alternative
hypotheses? (Look back at what you said for #11 and #12)!

\vspace{1in}

23. Did you reach similar conclusions using theory-based methods? Why do you
believe that is the case?

\vspace{1in}
